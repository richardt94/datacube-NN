{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making tools to use covariate xarrays with a Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading covariates and targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These should already exist in a bunch of pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('site_and_points.pkl','rb') as f:\n",
    "    final_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"quantile_img.pkl\",\"rb\") as f:\n",
    "    quant_raster = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seasonal means\n",
    "with open(\"mean_seasonal_FC.pkl\",\"rb\") as f:\n",
    "    seasonal_means = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_seas = seasonal_means.sel(variable='PV').rename({'season':'channel'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (y: 886, x: 659, channel: 4)>\n",
       "array([[[61.97203 , 56.99014 , 60.784644, 50.163485],\n",
       "        [59.686388, 56.539571, 62.130111, 49.612824],\n",
       "        ...,\n",
       "        [52.804433, 45.763796, 51.412143, 43.88654 ],\n",
       "        [56.514986, 48.027604, 53.945511, 45.846932]],\n",
       "\n",
       "       [[59.696613, 57.998884, 62.081184, 50.653793],\n",
       "        [58.84326 , 54.444835, 58.516161, 50.029311],\n",
       "        ...,\n",
       "        [54.473558, 47.502116, 53.673721, 44.763188],\n",
       "        [57.525812, 51.180986, 58.85907 , 48.93493 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[74.482983, 52.336733, 62.816531, 67.265901],\n",
       "        [76.309705, 53.302597, 62.732599, 68.337951],\n",
       "        ...,\n",
       "        [59.712529, 59.333012, 70.1329  , 53.606898],\n",
       "        [55.674188, 54.775554, 69.946958, 49.202397]],\n",
       "\n",
       "       [[75.849694, 51.32138 , 62.854182, 68.617417],\n",
       "        [75.589411, 52.836265, 63.55757 , 65.914851],\n",
       "        ...,\n",
       "        [60.414193, 60.326271, 70.482568, 54.457972],\n",
       "        [58.453094, 58.396196, 70.109053, 51.88663 ]]])\n",
       "Coordinates:\n",
       "  * y        (y) float64 -3.697e+06 -3.697e+06 ... -3.719e+06 -3.719e+06\n",
       "  * x        (x) float64 1.782e+06 1.782e+06 1.782e+06 ... 1.798e+06 1.798e+06\n",
       "  * channel  (channel) object 'summer' 'winter' 'autumn' 'spring'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PV_seas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'channel' (channel: 7)>\n",
       "array([0.01, 0.1 , 0.25, 0.5 , 0.75, 0.9 , 0.99])\n",
       "Coordinates:\n",
       "  * channel  (channel) float64 0.01 0.1 0.25 0.5 0.75 0.9 0.99"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_raster.channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "tpi = xr.open_rasterio('SOC_geotiff/TPI_ablers.tif')\n",
    "saga = xr.open_rasterio('SOC_geotiff/sagawetness_albers.tif')\n",
    "#need to make nodata non-numeric for standardisation to work correctly\n",
    "tpi = tpi.where(tpi!=tpi.nodatavals[0])\n",
    "saga = saga.where(saga!=saga.nodatavals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleID</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Northing</th>\n",
       "      <th>TC</th>\n",
       "      <th>Method</th>\n",
       "      <th>Year</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001_A1.2</td>\n",
       "      <td>338014.132</td>\n",
       "      <td>6370645.57</td>\n",
       "      <td>0.981252</td>\n",
       "      <td>CNS</td>\n",
       "      <td>2001</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1MIR</td>\n",
       "      <td>338014.132</td>\n",
       "      <td>6370645.57</td>\n",
       "      <td>0.600364</td>\n",
       "      <td>MIR</td>\n",
       "      <td>2001</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001_A6.2</td>\n",
       "      <td>338068.776</td>\n",
       "      <td>6370868.38</td>\n",
       "      <td>0.866419</td>\n",
       "      <td>CNS</td>\n",
       "      <td>2001</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A6MIR</td>\n",
       "      <td>338068.776</td>\n",
       "      <td>6370868.38</td>\n",
       "      <td>1.187051</td>\n",
       "      <td>MIR</td>\n",
       "      <td>2001</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001_A11.2</td>\n",
       "      <td>338182.533</td>\n",
       "      <td>6370550.16</td>\n",
       "      <td>0.772519</td>\n",
       "      <td>CNS</td>\n",
       "      <td>2001</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SampleID     Easting    Northing        TC Method  Year  \\\n",
       "0   2001_A1.2  338014.132  6370645.57  0.981252    CNS  2001   \n",
       "1       A1MIR  338014.132  6370645.57  0.600364    MIR  2001   \n",
       "2   2001_A6.2  338068.776  6370868.38  0.866419    CNS  2001   \n",
       "3       A6MIR  338068.776  6370868.38  1.187051    MIR  2001   \n",
       "4  2001_A11.2  338182.533  6370550.16  0.772519    CNS  2001   \n",
       "\n",
       "                                              points  \n",
       "0  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "1  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "2  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "3  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "4  Geometry({'type': 'Point', 'coordinates': (178...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a DataFrame with all the position and target information about the site measurements, and raster maps of the TPI and SAGA wetness, along with quantiles of photosynthetic vegetation cover observed by Landsat. We should combine these separate rasters into one huge multi-channel raster, then write a function to select from this raster and produce a 'window' around a site measurement for input into the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "topographic = xr.concat((saga,tpi),dim='band').rename({'band':'channel'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 886, 659)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topographic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot rename 'quantile' because it is not a variable or dimension in this dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-256-0fbca1fd935a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquant_raster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquant_raster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'quantile'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'channel'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36mrename\u001b[0;34m(self, new_name_or_name_dict, **names)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             name_dict = either_dict_or_kwargs(\n\u001b[1;32m   1234\u001b[0m                 new_name_or_name_dict, names, 'rename')\n\u001b[0;32m-> 1235\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_temp_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_temp_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mrename\u001b[0;34m(self, name_dict, inplace, **names)\u001b[0m\n\u001b[1;32m   2350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m                 raise ValueError(\"cannot rename %r because it is not a \"\n\u001b[0;32m-> 2352\u001b[0;31m                                  \"variable or dimension in this dataset\" % k)\n\u001b[0m\u001b[1;32m   2353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m         variables, coord_names, dims, indexes = self._rename_all(\n",
      "\u001b[0;31mValueError\u001b[0m: cannot rename 'quantile' because it is not a variable or dimension in this dataset"
     ]
    }
   ],
   "source": [
    "quant_raster = quant_raster.rename({'quantile':'channel'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars = xr.concat((topographic,quant_raster,PV_seas),dim='channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove incompatible metadata in the dimension that was concatenated\n",
    "import numpy as np; covars['channel'] = np.arange(len(covars['channel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'channel' (channel: 13)>\n",
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n",
       "Coordinates:\n",
       "  * channel  (channel) int64 0 1 2 3 4 5 6 7 8 9 10 11 12"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covars.channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create training/validation samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a point (x,y) and a specified buffer around it (in pixels), then returns a trimmed raster of the covariates around the point. It should deal with cases where the buffer zone intersects the edge of the covariate raster map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine resolution of rasters by differencing the spatial dimensions.\n",
    "#ensure that if the raster contains covariates from different sources that they are coregistered\n",
    "#to the same spatial coordinate sets otherwise this won't work and you'll end up with a bunch of\n",
    "#NaNs in your underlying numpy arrays.\n",
    "xres = covars.x[1]-covars.x[0]\n",
    "yres = covars.y[1]-covars.y[0]\n",
    "\n",
    "def sample_raster(row,bufferx=10,buffery=10):\n",
    "    LL = row['points']\n",
    "    sitex = LL.coords[0][0]\n",
    "    sitey = LL.coords[0][1]\n",
    "    \n",
    "    x = np.arange(sitex-bufferx*xres,sitex+(bufferx+1)*xres,xres)\n",
    "    y = np.arange(sitey-buffery*yres,sitey+(buffery+1)*yres,yres)\n",
    "    \n",
    "    sample_array = covars.reindex(x=x,method='nearest',tolerance=abs(xres/2)).reindex(y=y,method='nearest',tolerance=abs(yres/2))\n",
    "    \n",
    "    sample_array = sample_array.fillna(0)\n",
    "    \n",
    "    return sample_array.data\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may help to standardise the inputs for training. We can do this simply using built-in features of xarray before generating training samples. We can then either impute missing values (NaNs) on-the-fly using Keras or do it using our sample generating function while creating the training/validation set. It is less costly to do the latter because once it's done it will not need to be done again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars = (covars - covars.mean(dim=['x','y']))/covars.std(dim=['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 886, 659)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the standardised covariate raster - this will come in handy later on\n",
    "with open(\"standardised_NN_covars.pkl\",\"wb\") as f:\n",
    "    pickle.dump(covars,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating labelled datasets for training and validation\n",
    "We can now iterate through the dataframe and save the input data associated with each sample site in a directory in the 'normal' way for use with a Keras generator. This avoids loading every sample into RAM to train the NN. The labels are the measured SOC values in the dataframe. We will need to associate each row of the dataframe with a unique file on disk which can be read by the generator which feeds samples to Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2183"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.981252\n",
       "1    0.600364\n",
       "2    0.866419\n",
       "3    1.187051\n",
       "4    0.772519\n",
       "5    1.398617\n",
       "6    0.593211\n",
       "7    1.126836\n",
       "8    1.315066\n",
       "9    1.881963\n",
       "Name: TC, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.iloc[0:10]['TC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovarGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Feed trimmed covariate images for an NN\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,gen_df,batch_size = 32, shuffle = True):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.length = len(gen_df)//batch_size\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.gen_df = gen_df.sample(frac=1).reset_index(drop=True)\n",
    "        else:\n",
    "            self.gen_df = gen_df\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        slicedf = self.gen_df.iloc[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        y = np.array(slicedf['TC'])\n",
    "        X = np.stack(slicedf.apply(sample_raster,axis=1))\n",
    "        #channels-last is default for TF+Keras\n",
    "        X = np.moveaxis(X,1,3)\n",
    "        return (X,y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.gen_df = self.gen_df.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "testgen = CovarGenerator(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = testgen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 21, 21, 13)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = final_df.iloc[0:int(0.7*len(final_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = final_df.iloc[int(0.7*len(final_df)):int(0.85*len(final_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = final_df.iloc[int(0.85*len(final_df)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_gen = CovarGenerator(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_gen = CovarGenerator(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, SpatialDropout2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(8,kernel_size=10,activation='relu',input_shape=(21,21,13)))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "47/47 [==============================] - 21s 449ms/step - loss: 5.1021 - val_loss: 2.2716\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 19s 411ms/step - loss: 3.9467 - val_loss: 2.3584\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 18s 389ms/step - loss: 3.5312 - val_loss: 1.8127\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 18s 390ms/step - loss: 3.1296 - val_loss: 2.5660\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 17s 369ms/step - loss: 3.3275 - val_loss: 2.0768\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 19s 402ms/step - loss: 2.9234 - val_loss: 2.3308\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 17s 357ms/step - loss: 3.0341 - val_loss: 2.1161\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 18s 381ms/step - loss: 2.7500 - val_loss: 2.2516\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 18s 386ms/step - loss: 2.8533 - val_loss: 2.2947\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 17s 371ms/step - loss: 3.1796 - val_loss: 1.9854\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 19s 411ms/step - loss: 3.0738 - val_loss: 2.8349\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 20s 416ms/step - loss: 2.7291 - val_loss: 1.7948\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 17s 363ms/step - loss: 2.5115 - val_loss: 1.9546\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 18s 382ms/step - loss: 2.3689 - val_loss: 1.9852\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 19s 402ms/step - loss: 2.2296 - val_loss: 1.8602\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 18s 382ms/step - loss: 2.1637 - val_loss: 1.8645\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 18s 380ms/step - loss: 2.2234 - val_loss: 1.6571\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 19s 399ms/step - loss: 2.0651 - val_loss: 1.6816\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 18s 387ms/step - loss: 2.1618 - val_loss: 1.8290\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 18s 393ms/step - loss: 2.1314 - val_loss: 1.7642\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 18s 383ms/step - loss: 2.0752 - val_loss: 1.7547\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 18s 391ms/step - loss: 1.9821 - val_loss: 1.7216\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 18s 390ms/step - loss: 1.9622 - val_loss: 1.8795\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 17s 370ms/step - loss: 1.9496 - val_loss: 1.5874\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 19s 395ms/step - loss: 1.8007 - val_loss: 1.5918\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 17s 357ms/step - loss: 1.9655 - val_loss: 1.5641\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 19s 413ms/step - loss: 1.7379 - val_loss: 1.8455\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 16s 340ms/step - loss: 1.8500 - val_loss: 1.8679\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 20s 421ms/step - loss: 1.8445 - val_loss: 1.8858\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 18s 373ms/step - loss: 1.8513 - val_loss: 1.6729\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 18s 374ms/step - loss: 1.6556 - val_loss: 1.5672\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 18s 389ms/step - loss: 1.6428 - val_loss: 1.6564\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 19s 399ms/step - loss: 1.6503 - val_loss: 1.5824\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 18s 373ms/step - loss: 1.7518 - val_loss: 1.7562\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 18s 385ms/step - loss: 1.5002 - val_loss: 1.6237\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 18s 384ms/step - loss: 1.5252 - val_loss: 1.6605\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 19s 406ms/step - loss: 1.4912 - val_loss: 1.6492\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 18s 389ms/step - loss: 1.4952 - val_loss: 1.6357\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 17s 358ms/step - loss: 1.6266 - val_loss: 1.6614\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 19s 394ms/step - loss: 1.5089 - val_loss: 1.5749\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 18s 373ms/step - loss: 1.4425 - val_loss: 1.6181\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 18s 381ms/step - loss: 1.6187 - val_loss: 1.6590\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 17s 351ms/step - loss: 1.4719 - val_loss: 1.6156\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 18s 390ms/step - loss: 1.5040 - val_loss: 1.6842\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 17s 357ms/step - loss: 1.6279 - val_loss: 1.6699\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 19s 404ms/step - loss: 1.4763 - val_loss: 1.5183\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 18s 386ms/step - loss: 1.4967 - val_loss: 1.7040\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 18s 376ms/step - loss: 1.4401 - val_loss: 1.6481\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 17s 366ms/step - loss: 1.3186 - val_loss: 1.5162\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 18s 391ms/step - loss: 1.4346 - val_loss: 1.6488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6b28d26588>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(training_gen,epochs=50,validation_data=validation_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9286025583744049"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testgen = CovarGenerator(test_df)\n",
    "model.evaluate_generator(testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_generator(testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsoc = 0\n",
    "for batch,soc in training_gen:\n",
    "    tsoc += np.mean(soc)\n",
    "msoc = tsoc/len(training_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5734063676475403"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'conv2d_44/kernel:0' shape=(5, 5, 13, 8) dtype=float32>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (channel: 13)>\n",
       "array([ 1.619998e-16,  3.902013e-16,  7.919880e-16,  9.558375e-16,\n",
       "       -6.707803e-17, -2.570189e-17,  2.267899e-16, -1.490125e-15,\n",
       "        8.933352e-16,  5.919222e-17, -5.705040e-16,  6.489726e-16,\n",
       "       -1.007047e-15])\n",
       "Coordinates:\n",
       "  * channel  (channel) int64 0 1 2 3 4 5 6 7 8 9 10 11 12"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covars.mean(dim=['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (channel: 13)>\n",
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
       "Coordinates:\n",
       "  * channel  (channel) int64 0 1 2 3 4 5 6 7 8 9 10 11 12"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covars.std(dim=['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (channel: 13)>\n",
       "array([-0.037357, -0.243832,  0.477716,  0.557435,  0.268647,  0.097549,\n",
       "       -0.154819, -0.255622, -0.324444,  0.154503,  0.104352,  0.116006,\n",
       "       -0.331155])\n",
       "Coordinates:\n",
       "    y        float64 -3.704e+06\n",
       "    x        float64 1.789e+06\n",
       "  * channel  (channel) int64 0 1 2 3 4 5 6 7 8 9 10 11 12"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covars.isel(x=300,y=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sample_dc(row, dc, bufferx = 10, buffery = 10, xres = 25, yres = -25, product = 'fc_percentile_albers_annual', crs = 'EPSG:3577', **query):\n",
    "    LL = row['points']\n",
    "    sitex = LL.coords[0][0]\n",
    "    sitey = LL.coords[0][1]\n",
    "    \n",
    "    x = np.arange(sitex-bufferx*xres,sitex+(bufferx+1)*xres,xres)\n",
    "    y = np.arange(sitey-buffery*yres,sitey+(buffery+1)*yres,yres)\n",
    "    \n",
    "    covars = dc.load(product = product, x = (min((x[0],x[-1])),max((x[0],x[-1]))), y = (min((y[0],y[-1])),max((y[0],y[-1]))), crs = crs, **query)\n",
    "    \n",
    "    print(len(covars.variables))\n",
    "    \n",
    "    sample_array = covars.reindex(x=x,method='nearest',tolerance=abs(xres/2)).reindex(y=y,method='nearest',tolerance=abs(yres/2))\n",
    "    \n",
    "    sample_array = sample_array.fillna(0)\n",
    "    \n",
    "    return sample_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "dc = datacube.Datacube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trow = final_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "test_xr = sample_dc(trow,dc).isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mband_np = test_xr.to_array().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitex,sitey = trow['points'].coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1784613.2479390604"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sitex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3710538.5739176488"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sitey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'x': (sitex-300,sitex+300),\n",
    "    'y': (sitey-300,sitey+300),\n",
    "    'time': ('2001-03-01','2002-03-01')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (time: 1, x: 25, y: 25)\n",
       "Coordinates:\n",
       "  * time       (time) datetime64[ns] 2002-01-01\n",
       "  * y          (y) float64 -3.71e+06 -3.71e+06 ... -3.711e+06 -3.711e+06\n",
       "  * x          (x) float64 1.784e+06 1.784e+06 1.784e+06 ... 1.785e+06 1.785e+06\n",
       "Data variables:\n",
       "    BS_PC_10   (time, y, x) int8 0 0 4 18 19 22 19 7 4 4 ... 7 8 6 8 0 4 2 0 0 8\n",
       "    PV_PC_10   (time, y, x) int8 47 33 19 10 8 8 13 33 ... 30 26 31 37 39 40 37\n",
       "    NPV_PC_10  (time, y, x) int8 25 36 45 43 42 38 41 ... 21 14 18 17 21 19 17\n",
       "    BS_PC_50   (time, y, x) int8 1 7 19 36 38 39 33 13 8 ... 9 13 11 8 7 6 8 18\n",
       "    PV_PC_50   (time, y, x) int8 61 47 34 14 13 14 22 ... 38 41 40 44 50 52 47\n",
       "    NPV_PC_50  (time, y, x) int8 37 44 48 49 47 46 44 ... 46 47 47 43 41 42 36\n",
       "    BS_PC_90   (time, y, x) int8 6 17 31 45 44 48 42 23 ... 17 16 13 11 11 11 20\n",
       "    PV_PC_90   (time, y, x) int8 70 57 51 29 27 21 32 ... 75 83 81 81 76 79 72\n",
       "    NPV_PC_90  (time, y, x) int8 45 49 53 52 54 55 50 ... 53 57 56 54 50 50 43\n",
       "Attributes:\n",
       "    crs:      EPSG:3577"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.load(product = 'fc_percentile_albers_annual',**query, crs='EPSG:3577')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = dc.list_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "36                                             EPSG:4326\n",
       "88                                             EPSG:3577\n",
       "32                                             EPSG:4326\n",
       "99                                             EPSG:3577\n",
       "53     GEOGCS[\"GEOCENTRIC DATUM of AUSTRALIA\",DATUM[\"...\n",
       "                             ...                        \n",
       "97                                             EPSG:3577\n",
       "100                                            EPSG:3577\n",
       "85                                             EPSG:3577\n",
       "101                                            EPSG:3577\n",
       "84                                             EPSG:3577\n",
       "Name: crs, Length: 77, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod['crs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geometry(POINT (1784613.24793906 -3710538.57391765), EPSG:3577)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trow['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = dc.list_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('y', 'x')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod[prod['name']=='fc_percentile_albers_annual']['spatial_dimensions'].array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-300., -275., -250., -225., -200., -175., -150., -125., -100.,\n",
       "        -75.,  -50.,  -25.,    0.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(-300.,25.,25.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geometry(POINT (151.270161902695 -32.7902091714388), EPSG:4326)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trow['points'].to_crs(CRS('EPSG:4326'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacube.utils.geometry import CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifffile.imsave('testTIF.tif',data=mband_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geometry(POINT (1784613.24793906 -3710538.57391765), EPSG:3577)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['points'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'datacube_NN.model_development' from '/g/data/r78/rlt118/datacube-NN/datacube_NN/model_development.py'>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datacube_NN import model_development\n",
    "import imp\n",
    "imp.reload(model_development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvester = model_development.DatacubeHarvester(dc,'fc_percentile_albers_annual',time=('2013-05-01','2014-05-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': -25, 'x': 25}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harvester.resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harvester.pixel_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': -250, 'x': 250}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harvester.spatial_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvester.process('test_data',sample,'points','TC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = final_df.sample(n=10).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleID</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Northing</th>\n",
       "      <th>TC</th>\n",
       "      <th>Method</th>\n",
       "      <th>Year</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008_tj2_0_10</td>\n",
       "      <td>340203.7000</td>\n",
       "      <td>6366900.300</td>\n",
       "      <td>4.219505</td>\n",
       "      <td>NIR</td>\n",
       "      <td>2008</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001_A85_0_10</td>\n",
       "      <td>339686.0490</td>\n",
       "      <td>6369372.820</td>\n",
       "      <td>2.478898</td>\n",
       "      <td>CNS</td>\n",
       "      <td>2001</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006_f148_0_10</td>\n",
       "      <td>338110.0000</td>\n",
       "      <td>6372270.000</td>\n",
       "      <td>1.215441</td>\n",
       "      <td>NIR</td>\n",
       "      <td>2006</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d100MIR</td>\n",
       "      <td>341493.6842</td>\n",
       "      <td>6368399.017</td>\n",
       "      <td>2.776235</td>\n",
       "      <td>MIR</td>\n",
       "      <td>2004</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV299</td>\n",
       "      <td>343823.8940</td>\n",
       "      <td>6382086.010</td>\n",
       "      <td>3.454304</td>\n",
       "      <td>MIR</td>\n",
       "      <td>2004</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (179...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B28MIR</td>\n",
       "      <td>340333.1410</td>\n",
       "      <td>6369596.270</td>\n",
       "      <td>2.250575</td>\n",
       "      <td>MIR</td>\n",
       "      <td>2002</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hvd20_1</td>\n",
       "      <td>337484.8000</td>\n",
       "      <td>6382815.500</td>\n",
       "      <td>2.459440</td>\n",
       "      <td>CNS</td>\n",
       "      <td>2010</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f073MIR</td>\n",
       "      <td>338499.0000</td>\n",
       "      <td>6372880.000</td>\n",
       "      <td>0.869703</td>\n",
       "      <td>MIR</td>\n",
       "      <td>2006</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C102MIR</td>\n",
       "      <td>338868.4120</td>\n",
       "      <td>6369044.610</td>\n",
       "      <td>4.459809</td>\n",
       "      <td>MIR</td>\n",
       "      <td>2003</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HV239</td>\n",
       "      <td>345163.5750</td>\n",
       "      <td>6369984.240</td>\n",
       "      <td>1.729756</td>\n",
       "      <td>MIR</td>\n",
       "      <td>2004</td>\n",
       "      <td>Geometry({'type': 'Point', 'coordinates': (179...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SampleID      Easting     Northing        TC Method  Year  \\\n",
       "0   2008_tj2_0_10  340203.7000  6366900.300  4.219505    NIR  2008   \n",
       "1   2001_A85_0_10  339686.0490  6369372.820  2.478898    CNS  2001   \n",
       "2  2006_f148_0_10  338110.0000  6372270.000  1.215441    NIR  2006   \n",
       "3         d100MIR  341493.6842  6368399.017  2.776235    MIR  2004   \n",
       "4           HV299  343823.8940  6382086.010  3.454304    MIR  2004   \n",
       "5          B28MIR  340333.1410  6369596.270  2.250575    MIR  2002   \n",
       "6         hvd20_1  337484.8000  6382815.500  2.459440    CNS  2010   \n",
       "7         f073MIR  338499.0000  6372880.000  0.869703    MIR  2006   \n",
       "8         C102MIR  338868.4120  6369044.610  4.459809    MIR  2003   \n",
       "9           HV239  345163.5750  6369984.240  1.729756    MIR  2004   \n",
       "\n",
       "                                              points  \n",
       "0  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "1  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "2  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "3  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "4  Geometry({'type': 'Point', 'coordinates': (179...  \n",
       "5  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "6  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "7  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "8  Geometry({'type': 'Point', 'coordinates': (178...  \n",
       "9  Geometry({'type': 'Point', 'coordinates': (179...  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "test_read_array = tifffile.imread('test_data/0.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 21, 21)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_read_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpt = sample.iloc[0]['points']\n",
    "sitex,sitey = tpt.coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "99    EPSG:3577\n",
       "Name: crs, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod = dc.list_products()\n",
    "prod[prod['name']=='fc_percentile_albers_annual'].crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dc_xr = dc.load(product='fc_percentile_albers_annual',x=(sitex-267.5,sitex+267.5),y=(sitey-267.5,sitey+267.5),crs='EPSG:3577',time=('2013-05-01','2014-05-01')).to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dc_xr = test_dc_xr.isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dc_xr = test_dc_xr.reindex(x=sitex+np.arange(-250,275,25),y=sitey+np.arange(250,-275,-25),method='nearest',tolerance=12.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dc_array = test_dc_xr.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.array_equal(test_dc_array,test_read_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 7,  8,  9, ...,  2,  1,  2],\n",
       "        [ 4,  1,  2, ...,  3,  3,  1],\n",
       "        [ 1,  3,  8, ...,  2,  3,  1],\n",
       "        ...,\n",
       "        [ 0, 15,  4, ..., 11, 10,  7],\n",
       "        [11,  8,  5, ..., 11,  6,  0],\n",
       "        [ 8,  7,  1, ...,  5,  2,  8]],\n",
       "\n",
       "       [[45, 42, 42, ..., 56, 56, 57],\n",
       "        [47, 43, 53, ..., 55, 57, 58],\n",
       "        [45, 46, 50, ..., 54, 52, 55],\n",
       "        ...,\n",
       "        [21, 40, 53, ..., 47, 48, 49],\n",
       "        [36, 40, 51, ..., 43, 46, 47],\n",
       "        [38, 44, 45, ..., 53, 47, 52]],\n",
       "\n",
       "       [[25, 23, 14, ..., 27, 26, 28],\n",
       "        [27, 23, 18, ..., 20, 19, 26],\n",
       "        [27, 21, 21, ..., 32, 20, 23],\n",
       "        ...,\n",
       "        [40, 24, 26, ...,  4, 11, 15],\n",
       "        [23, 39, 17, ...,  9,  8, 17],\n",
       "        [24, 14, 27, ..., 15, 13,  9]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[17, 20, 23, ...,  6,  7,  7],\n",
       "        [19, 23, 21, ..., 11,  9,  9],\n",
       "        [24, 21, 16, ...,  9, 15,  7],\n",
       "        ...,\n",
       "        [17, 21, 12, ..., 22, 16, 12],\n",
       "        [15, 13, 12, ..., 18, 18, 19],\n",
       "        [15, 12, 10, ..., 13, 16, 21]],\n",
       "\n",
       "       [[60, 64, 68, ..., 62, 70, 65],\n",
       "        [55, 60, 69, ..., 64, 66, 73],\n",
       "        [63, 62, 62, ..., 65, 66, 69],\n",
       "        ...,\n",
       "        [47, 52, 67, ..., 81, 75, 72],\n",
       "        [61, 49, 75, ..., 76, 81, 72],\n",
       "        [62, 79, 71, ..., 76, 73, 79]],\n",
       "\n",
       "       [[44, 43, 37, ..., 40, 40, 37],\n",
       "        [43, 43, 36, ..., 40, 38, 41],\n",
       "        [41, 38, 36, ..., 41, 42, 39],\n",
       "        ...,\n",
       "        [69, 39, 39, ..., 40, 40, 46],\n",
       "        [48, 46, 38, ..., 45, 40, 44],\n",
       "        [51, 45, 46, ..., 38, 40, 31]]], dtype=int8)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_read_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  4, 10, ..., 10,  7,  8],\n",
       "        [ 2,  4,  6, ..., 13,  9, 11],\n",
       "        [ 3,  4,  0, ..., 12,  3,  3],\n",
       "        ...,\n",
       "        [ 2,  4,  4, ..., 10, 11, 14],\n",
       "        [ 3,  4,  7, ..., 14, 15, 16],\n",
       "        [ 1,  3,  4, ..., 11, 12, 11]],\n",
       "\n",
       "       [[57, 44, 41, ..., 41, 44, 45],\n",
       "        [52, 46, 49, ..., 45, 43, 46],\n",
       "        [55, 40, 35, ..., 44, 38, 26],\n",
       "        ...,\n",
       "        [58, 53, 50, ..., 39, 40, 36],\n",
       "        [58, 56, 50, ..., 47, 43, 41],\n",
       "        [61, 57, 51, ..., 53, 51, 52]],\n",
       "\n",
       "       [[30, 30, 30, ..., 12, 16, 17],\n",
       "        [29, 24, 23, ..., 12, 16, 10],\n",
       "        [27, 32, 34, ..., 14, 17, 30],\n",
       "        ...,\n",
       "        [33, 28, 20, ..., 27, 22, 20],\n",
       "        [30, 25, 26, ..., 19, 17,  9],\n",
       "        [29, 28, 26, ..., 19, 17, 19]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4, 14, 20, ..., 26, 22, 22],\n",
       "        [ 6, 11, 12, ..., 23, 21, 23],\n",
       "        [10, 10, 24, ..., 26, 21, 22],\n",
       "        ...,\n",
       "        [ 4,  5, 16, ..., 23, 23, 28],\n",
       "        [ 4,  7, 22, ..., 19, 21, 25],\n",
       "        [ 4,  6, 17, ..., 17, 19, 17]],\n",
       "\n",
       "       [[68, 61, 57, ..., 68, 67, 66],\n",
       "        [67, 67, 66, ..., 71, 64, 70],\n",
       "        [70, 60, 49, ..., 66, 66, 51],\n",
       "        ...,\n",
       "        [64, 60, 63, ..., 58, 60, 57],\n",
       "        [64, 66, 62, ..., 63, 62, 63],\n",
       "        [68, 63, 58, ..., 68, 69, 68]],\n",
       "\n",
       "       [[39, 45, 44, ..., 42, 41, 38],\n",
       "        [42, 46, 42, ..., 37, 45, 39],\n",
       "        [41, 51, 54, ..., 38, 54, 62],\n",
       "        ...,\n",
       "        [38, 41, 39, ..., 43, 40, 44],\n",
       "        [38, 38, 36, ..., 37, 41, 42],\n",
       "        [35, 37, 42, ..., 33, 35, 34]]], dtype=int8)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_read_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[11, 21, 17, ...,  3,  4,  5],\n",
       "        [ 5, 10, 14, ...,  3,  4,  4],\n",
       "        [ 9,  9,  4, ...,  4,  4,  4],\n",
       "        ...,\n",
       "        [ 9,  6, 11, ..., 13,  9,  8],\n",
       "        [10, 11,  9, ...,  9, 10,  8],\n",
       "        [13,  8,  7, ..., 10,  9,  8]],\n",
       "\n",
       "       [[43, 39, 35, ..., 37, 40, 36],\n",
       "        [45, 41, 40, ..., 37, 37, 33],\n",
       "        [44, 44, 44, ..., 35, 34, 30],\n",
       "        ...,\n",
       "        [12, 19, 32, ..., 51, 45, 32],\n",
       "        [14, 23, 33, ..., 59, 48, 28],\n",
       "        [30, 32, 34, ..., 55, 42, 28]],\n",
       "\n",
       "       [[20, 19, 19, ..., 34, 18, 18],\n",
       "        [28, 26, 26, ..., 34, 19, 18],\n",
       "        [21, 23, 23, ..., 36, 19, 31],\n",
       "        ...,\n",
       "        [33, 30, 26, ..., 10, 13, 20],\n",
       "        [31, 32, 27, ..., 10, 10, 20],\n",
       "        [30, 29, 30, ..., 13, 16, 18]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[28, 34, 39, ..., 12, 12, 15],\n",
       "        [22, 25, 29, ..., 12, 12, 14],\n",
       "        [28, 20, 18, ..., 13, 13, 14],\n",
       "        ...,\n",
       "        [36, 33, 22, ..., 29, 25, 25],\n",
       "        [41, 35, 25, ..., 28, 27, 25],\n",
       "        [25, 23, 19, ..., 27, 27, 29]],\n",
       "\n",
       "       [[62, 50, 45, ..., 59, 73, 71],\n",
       "        [65, 54, 53, ..., 59, 71, 70],\n",
       "        [54, 56, 60, ..., 56, 70, 56],\n",
       "        ...,\n",
       "        [43, 50, 55, ..., 66, 68, 64],\n",
       "        [45, 48, 52, ..., 70, 68, 63],\n",
       "        [48, 53, 52, ..., 71, 69, 64]],\n",
       "\n",
       "       [[38, 36, 44, ..., 59, 56, 56],\n",
       "        [44, 36, 39, ..., 59, 58, 58],\n",
       "        [39, 45, 44, ..., 61, 61, 63],\n",
       "        ...,\n",
       "        [52, 51, 51, ..., 31, 38, 64],\n",
       "        [46, 47, 49, ..., 28, 41, 60],\n",
       "        [45, 47, 51, ..., 31, 44, 64]]], dtype=int8)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
